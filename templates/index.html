<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image to Text (OCR)</title>
    <script src='https://unpkg.com/tesseract.js@v4.1.1/dist/tesseract.min.js'></script>
    <style>
        :root {
            --bg-primary: #1a1a1a;
            --bg-secondary: #2d2d2d;
            --text-primary: #ffffff;
            --text-secondary: #b3b3b3;
            --accent: #6366f1;
            --accent-hover: #818cf8;
            --error-bg: #442626;
            --error-border: #dc2626;
            --error-text: #ef4444;
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
            background-color: var(--bg-primary);
            color: var(--text-primary);
            max-width: 1000px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
        }

        .container {
            display: flex;
            flex-direction: column;
            gap: 24px;
        }

        .header {
            display: flex;
            align-items: flex-start;
            gap: 16px;
            margin-bottom: 16px;
        }

        .header h1 {
            margin: 0;
            font-size: 2.5rem;
            background: linear-gradient(to right, var(--accent), var(--accent-hover));
            -webkit-background-clip: text;
            background-clip: text;
            color: transparent;
        }

        .subheading {
            margin: 4px 0 0 0;
            font-size: 0.875rem;
            color: var(--text-secondary);
        }

        .input-group {
            display: flex;
            gap: 12px;
            flex-wrap: wrap;
        }

        .preview-container {
            position: relative;
            max-width: 100%;
            margin-top: 20px;
            background: var(--bg-secondary);
            padding: 16px;
            border-radius: 8px;
            overflow: hidden;
        }

        #preview {
            max-width: 100%;
            border-radius: 4px;
        }

        #canvas-overlay {
            position: absolute;
            top: 16px;
            left: 16px;
            pointer-events: none;
        }

        #result {
            white-space: pre-wrap;
            padding: 16px;
            border-radius: 8px;
            background: var(--bg-secondary);
            color: var(--text-primary);
            font-family: 'Roboto Mono', monospace;
            font-size: 0.9rem;
            line-height: 1.5;
        }

        .progress {
            padding: 12px 16px;
            background: var(--bg-secondary);
            border-radius: 8px;
            color: var(--text-secondary);
        }

        .error {
            color: var(--error-text);
            background: var(--error-bg);
            border: 1px solid var(--error-border);
            padding: 12px 16px;
            border-radius: 8px;
        }

        button {
            padding: 10px 20px;
            background: var(--accent);
            color: white;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            font-weight: 500;
            transition: all 0.2s ease;
        }

        button:hover:not(:disabled) {
            background: var(--accent-hover);
            transform: translateY(-1px);
        }

        button:disabled {
            background: var(--bg-secondary);
            color: var(--text-secondary);
            cursor: not-allowed;
        }

        .file-input-wrapper {
            position: relative;
            display: inline-block;
        }

        .file-input-wrapper input[type="file"] {
            display: none;
        }

        .file-input-wrapper label {
            padding: 10px 20px;
            background: var(--bg-secondary);
            color: var(--text-primary);
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.2s ease;
            display: inline-flex;
            align-items: center;
            gap: 8px;
        }

        .file-input-wrapper label:hover {
            background: #3d3d3d;
        }

        #camera-feed {
            width: 100%;
            max-width: 640px;
            background: var(--bg-secondary);
            border-radius: 8px;
            display: none;
        }

        .camera-controls {
            display: none;
            gap: 12px;
            margin-top: 12px;
        }

        .icon {
            width: 20px;
            height: 20px;
            fill: currentColor;
        }

        .camera-select {
            padding: 8px 12px;
            background: var(--bg-secondary);
            color: var(--text-primary);
            border: 1px solid var(--accent);
            border-radius: 8px;
            cursor: pointer;
            font-size: 14px;
        }

        .camera-select:focus {
            outline: none;
            border-color: var(--accent-hover);
        }

        .preprocessing-controls {
            background: var(--bg-secondary);
            padding: 16px;
            border-radius: 8px;
            margin-top: 12px;
        }

        .preprocessing-controls h3 {
            margin: 0 0 12px 0;
            font-size: 1.1rem;
            color: var(--text-primary);
        }

        .control-group {
            display: flex;
            flex-wrap: wrap;
            gap: 16px;
        }

        .control-group label {
            display: flex;
            align-items: center;
            gap: 8px;
            color: var(--text-primary);
            cursor: pointer;
        }

        .threshold-controls {
            display: flex;
            align-items: center;
            gap: 8px;
            margin-top: 8px;
        }

        .threshold-controls input[type="range"] {
            width: 200px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <div>
                <h1>Image to Text (OCR)</h1>
                <p class="subheading">by Bautista, BJI - CS 3B</p>
            </div>
        </div>
        
        <div class="input-group">
            <div class="file-input-wrapper">
                <input type="file" id="image-input" accept="image/*">
                <label for="image-input">
                    <svg class="icon" viewBox="0 0 24 24">
                        <path d="M19,13H13V19H11V13H5V11H11V5H13V11H19V13Z" />
                    </svg>
                    Choose Image
                </label>
            </div>
            <button onclick="toggleCamera()" id="camera-btn">
                <svg class="icon" viewBox="0 0 24 24">
                    <path d="M12,10L11.06,12.06L9,13L11.06,13.94L12,16L12.94,13.94L15,13L12.94,12.06L12,10M20,5H16.83L15,3H9L7.17,5H4A2,2 0 0,0 2,7V19A2,2 0 0,0 4,21H20A2,2 0 0,0 22,19V7A2,2 0 0,0 20,5M20,19H4V7H8.05L9.88,5H14.12L15.95,7H20V19M12,8A5,5 0 0,0 7,13A5,5 0 0,0 12,18A5,5 0 0,0 17,13A5,5 0 0,0 12,8" />
                </svg>
                Use Camera
            </button>
            <button onclick="processImage()" id="process-btn">Process Image</button>
        </div>

        <div class="preprocessing-controls">
            <h3>Image Preprocessing</h3>
            <div class="control-group">
                <label>
                    <input type="checkbox" id="grayscale" checked>
                    Convert to Grayscale
                </label>
                <label>
                    <input type="checkbox" id="auto-contrast" checked>
                    Auto Contrast
                </label>
                <label>
                    <input type="checkbox" id="denoise" checked>
                    Reduce Noise
                </label>
                <label>
                    <input type="checkbox" id="threshold">
                    Threshold
                </label>
                <div class="threshold-controls" id="threshold-controls" style="display: none;">
                    <input type="range" id="threshold-value" min="0" max="255" value="128">
                    <span id="threshold-display">128</span>
                </div>
            </div>
        </div>

        <video id="camera-feed" autoplay playsinline></video>
        
        <div class="camera-controls" id="camera-controls">
            <select id="camera-select" class="camera-select">
                <option value="">Loading cameras...</option>
            </select>
            <button onclick="captureImage()" id="capture-btn">Capture</button>
            <button onclick="toggleCamera()" id="stop-camera-btn">Stop Camera</button>
        </div>

        <div class="preview-container">
            <img id="preview">
            <canvas id="canvas-overlay"></canvas>
        </div>
        
        <div class="progress" id="progress">Ready to process images</div>
        
        <div id="result"></div>
    </div>

    <script>
        let worker = null;
        let scheduler = null;
        let stream = null;
        let cameras = [];

        async function initWorker() {
            try {
                scheduler = Tesseract.createScheduler();
                worker = await Tesseract.createWorker({
                    logger: message => {
                        const progress = document.getElementById('progress');
                        if (message.status === 'recognizing text') {
                            progress.textContent = `Processing: ${(message.progress * 100).toFixed(2)}%`;
                            progress.className = 'progress';
                        } else {
                            progress.textContent = `Status: ${message.status}`;
                            progress.className = 'progress';
                        }
                    }
                });
                
                await worker.loadLanguage('eng');
                await worker.initialize('eng');
                await scheduler.addWorker(worker);
                
                document.getElementById('process-btn').disabled = false;
                document.getElementById('progress').textContent = 'Ready to process images';
            } catch (error) {
                console.error('Worker initialization failed:', error);
                const progress = document.getElementById('progress');
                progress.textContent = `Failed to initialize OCR engine: ${error.message || 'Unknown error'}`;
                progress.className = 'progress error';
            }
        }

        // Initialize the worker
        document.getElementById('process-btn').disabled = true;
        document.getElementById('progress').textContent = 'Initializing OCR engine...';
        initWorker();

        async function drawBoundingBoxes(words, imageWidth, imageHeight) {
            const canvas = document.getElementById('canvas-overlay');
            const ctx = canvas.getContext('2d');
            
            // Set canvas size to match the image
            canvas.width = imageWidth;
            canvas.height = imageHeight;
            
            // Clear previous drawings
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            // Set styling for the boxes
            ctx.strokeStyle = '#6366f1';
            ctx.lineWidth = 2;
            ctx.font = '14px Inter';
            ctx.fillStyle = '#6366f1';
            
            words.forEach(word => {
                const { bbox } = word;
                const x = bbox.x0;
                const y = bbox.y0;
                const width = bbox.x1 - bbox.x0;
                const height = bbox.y1 - bbox.y0;
                
                // Draw rectangle
                ctx.strokeRect(x, y, width, height);
                
                // Draw confidence score
                const confidence = (word.confidence * 100).toFixed(0);
                ctx.fillText(`${confidence}%`, x, y - 5);
            });
        }

        // Function to preprocess the image
        async function preprocessImage(imageData) {
            const canvas = document.createElement('canvas');
            const ctx = canvas.getContext('2d');
            
            // Set canvas size to match image
            canvas.width = imageData.width;
            canvas.height = imageData.height;
            
            // Draw original image
            ctx.putImageData(imageData, 0, 0);
            
            // Get current preprocessing settings
            const useGrayscale = document.getElementById('grayscale').checked;
            const useAutoContrast = document.getElementById('auto-contrast').checked;
            const useDenoise = document.getElementById('denoise').checked;
            const useThreshold = document.getElementById('threshold').checked;
            const thresholdValue = document.getElementById('threshold-value').value;
            
            // Get image data
            let data = ctx.getImageData(0, 0, canvas.width, canvas.height);
            let pixels = data.data;
            
            // Convert to grayscale if enabled
            if (useGrayscale) {
                for (let i = 0; i < pixels.length; i += 4) {
                    const avg = (pixels[i] + pixels[i + 1] + pixels[i + 2]) / 3;
                    pixels[i] = pixels[i + 1] = pixels[i + 2] = avg;
                }
            }
            
            // Apply auto contrast if enabled
            if (useAutoContrast) {
                let min = 255;
                let max = 0;
                
                // Find min and max values
                for (let i = 0; i < pixels.length; i += 4) {
                    const value = pixels[i];
                    if (value < min) min = value;
                    if (value > max) max = value;
                }
                
                // Apply contrast stretching
                const range = max - min;
                for (let i = 0; i < pixels.length; i += 4) {
                    pixels[i] = pixels[i + 1] = pixels[i + 2] = 
                        ((pixels[i] - min) / range) * 255;
                }
            }
            
            // Apply noise reduction if enabled
            if (useDenoise) {
                const tempPixels = new Uint8ClampedArray(pixels.length);
                for (let i = 0; i < pixels.length; i += 4) {
                    const x = (i / 4) % canvas.width;
                    const y = Math.floor((i / 4) / canvas.width);
                    
                    if (x > 0 && x < canvas.width - 1 && y > 0 && y < canvas.height - 1) {
                        // Apply 3x3 median filter
                        const values = [];
                        for (let dy = -1; dy <= 1; dy++) {
                            for (let dx = -1; dx <= 1; dx++) {
                                const index = i + (dy * canvas.width + dx) * 4;
                                values.push(pixels[index]);
                            }
                        }
                        values.sort((a, b) => a - b);
                        const median = values[4]; // Middle value
                        tempPixels[i] = tempPixels[i + 1] = tempPixels[i + 2] = median;
                        tempPixels[i + 3] = pixels[i + 3];
                    } else {
                        tempPixels[i] = pixels[i];
                        tempPixels[i + 1] = pixels[i + 1];
                        tempPixels[i + 2] = pixels[i + 2];
                        tempPixels[i + 3] = pixels[i + 3];
                    }
                }
                pixels.set(tempPixels);
            }
            
            // Apply thresholding if enabled
            if (useThreshold) {
                for (let i = 0; i < pixels.length; i += 4) {
                    const value = pixels[i] > thresholdValue ? 255 : 0;
                    pixels[i] = pixels[i + 1] = pixels[i + 2] = value;
                }
            }
            
            // Update canvas with processed image
            ctx.putImageData(data, 0, 0);
            return canvas.toDataURL();
        }

        // Modify the processImage function to use preprocessing
        async function processImage() {
            const input = document.getElementById('image-input');
            const preview = document.getElementById('preview');
            const result = document.getElementById('result');
            const progress = document.getElementById('progress');
            const processBtn = document.getElementById('process-btn');

            if (!worker) {
                progress.textContent = 'OCR engine not initialized. Please refresh the page.';
                progress.className = 'progress error';
                return;
            }

            let imageFile;
            if (input.files && input.files[0]) {
                imageFile = input.files[0];
            } else if (preview.src && preview.src.startsWith('data:image')) {
                const response = await fetch(preview.src);
                imageFile = await response.blob();
            } else {
                alert('Please select an image or capture one from camera.');
                return;
            }
            
            // Show image preview
            const imageUrl = URL.createObjectURL(imageFile);
            preview.src = imageUrl;
            
            // Clear previous results and disable button
            result.textContent = '';
            progress.textContent = 'Starting preprocessing...';
            progress.className = 'progress';
            processBtn.disabled = true;

            try {
                // Wait for the image to load
                await new Promise(resolve => {
                    preview.onload = resolve;
                });

                // Create a canvas for preprocessing
                const canvas = document.createElement('canvas');
                const ctx = canvas.getContext('2d');
                canvas.width = preview.naturalWidth;
                canvas.height = preview.naturalHeight;
                ctx.drawImage(preview, 0, 0);
                
                // Get image data for preprocessing
                const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
                
                // Preprocess the image
                progress.textContent = 'Preprocessing image...';
                const processedImageUrl = await preprocessImage(imageData);
                
                // Update preview with processed image
                preview.src = processedImageUrl;
                
                // Perform OCR on processed image
                progress.textContent = 'Performing OCR...';
                const response = await worker.recognize(processedImageUrl);
                
                if (response && response.data) {
                    result.textContent = response.data.text;
                    progress.textContent = 'Processing complete!';
                    
                    // Draw bounding boxes
                    await drawBoundingBoxes(
                        response.data.words,
                        preview.naturalWidth,
                        preview.naturalHeight
                    );
                } else {
                    throw new Error('No text was extracted from the image');
                }
            } catch (error) {
                console.error('OCR processing failed:', error);
                result.textContent = '';
                progress.textContent = `Error: ${error.message || 'Failed to process image'}`;
                progress.className = 'progress error';
            } finally {
                processBtn.disabled = false;
            }
        }

        // Function to populate camera selection
        async function getCameraDevices() {
            try {
                const devices = await navigator.mediaDevices.enumerateDevices();
                cameras = devices.filter(device => device.kind === 'videoinput');
                
                const cameraSelect = document.getElementById('camera-select');
                cameraSelect.innerHTML = '';
                
                cameras.forEach((camera, index) => {
                    const option = document.createElement('option');
                    option.value = camera.deviceId;
                    option.text = camera.label || `Camera ${index + 1}`;
                    cameraSelect.appendChild(option);
                });

                if (cameras.length === 0) {
                    const option = document.createElement('option');
                    option.value = '';
                    option.text = 'No cameras found';
                    cameraSelect.appendChild(option);
                }
            } catch (error) {
                console.error('Error getting camera devices:', error);
                const cameraSelect = document.getElementById('camera-select');
                cameraSelect.innerHTML = '<option value="">Error loading cameras</option>';
            }
        }

        // Modified toggleCamera function to use selected camera
        async function toggleCamera() {
            const cameraFeed = document.getElementById('camera-feed');
            const cameraControls = document.getElementById('camera-controls');
            const cameraSelect = document.getElementById('camera-select');
            
            if (stream) {
                // Stop the camera
                stream.getTracks().forEach(track => track.stop());
                stream = null;
                cameraFeed.style.display = 'none';
                cameraControls.style.display = 'none';
                return;
            }

            try {
                // Get selected camera ID
                const selectedCamera = cameraSelect.value;
                
                // If no camera is selected and we have cameras available, use the first one
                const constraints = {
                    video: {
                        deviceId: selectedCamera ? { exact: selectedCamera } : undefined,
                        width: { ideal: 1920 },
                        height: { ideal: 1080 }
                    }
                };

                stream = await navigator.mediaDevices.getUserMedia(constraints);
                cameraFeed.srcObject = stream;
                cameraFeed.style.display = 'block';
                cameraControls.style.display = 'flex';

                // Get the list of cameras if we haven't already
                if (cameras.length === 0) {
                    await getCameraDevices();
                }
            } catch (error) {
                console.error('Camera access failed:', error);
                alert('Failed to access camera: ' + (error.message || 'Unknown error'));
            }
        }

        async function captureImage() {
            const cameraFeed = document.getElementById('camera-feed');
            const preview = document.getElementById('preview');
            
            // Create a canvas to capture the image
            const canvas = document.createElement('canvas');
            canvas.width = cameraFeed.videoWidth;
            canvas.height = cameraFeed.videoHeight;
            
            // Draw the video frame to the canvas
            const ctx = canvas.getContext('2d');
            ctx.drawImage(cameraFeed, 0, 0);
            
            // Convert to data URL and set as preview
            preview.src = canvas.toDataURL('image/png');
            
            // Stop the camera
            await toggleCamera();
            
            // Process the captured image
            await processImage();
        }

        // Add event listener for camera selection change
        document.getElementById('camera-select').addEventListener('change', async function() {
            if (stream) {
                // If camera is active, restart it with new selection
                await toggleCamera(); // Stop current stream
                await toggleCamera(); // Start new stream with selected camera
            }
        });

        // Request camera permissions and populate camera list when camera button is first clicked
        document.getElementById('camera-btn').addEventListener('click', async function() {
            if (cameras.length === 0) {
                try {
                    // First request camera permission
                    const initialStream = await navigator.mediaDevices.getUserMedia({ video: true });
                    initialStream.getTracks().forEach(track => track.stop()); // Stop the initial stream
                    
                    // Now we can get the camera list
                    await getCameraDevices();
                } catch (error) {
                    console.error('Failed to get camera permission:', error);
                    alert('Failed to get camera permission: ' + (error.message || 'Unknown error'));
                }
            }
            toggleCamera();
        });

        // Handle file input change
        document.getElementById('image-input').addEventListener('change', function(e) {
            if (this.files && this.files[0]) {
                const preview = document.getElementById('preview');
                preview.src = URL.createObjectURL(this.files[0]);
            }
        });

        // Add event listener for threshold checkbox
        document.getElementById('threshold').addEventListener('change', function() {
            document.getElementById('threshold-controls').style.display = 
                this.checked ? 'flex' : 'none';
        });

        // Add event listener for threshold value
        document.getElementById('threshold-value').addEventListener('input', function() {
            document.getElementById('threshold-display').textContent = this.value;
        });
    </script>
</body>
</html> 